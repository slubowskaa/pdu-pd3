library(XML)
library(dplyr)
xml2csv <- function(input,output){
xmlParse(input) %>% getNodeSet(path = "//row") %>%
XML:::xmlAttrsToDataFrame() %>% write.csv(output)
}
xml2csv("../data/gaming/Posts.xml",
"../data/Posts-Gaming.csv")
xml2csv("../data/gaming/Users.xml",
"../data/Users-Gaming.csv")
xml2csv("../data/chess/Posts.xml",
"../data/Posts-Chess.csv")
xml2csv("../data/chess/Users.xml",
"../data/Users-Chess.csv")
xml2csv("../data/bioinformatics/Posts.xml",
"../data/Posts-Bioinformatics.csv")
xml2csv("../data/bioinformatics/Users.xml",
"../data/Users-Bioinformatics.csv")
install.packages("XML")
library(XML)
library(dplyr)
xml2csv <- function(input,output){
xmlParse(input) %>% getNodeSet(path = "//row") %>%
XML:::xmlAttrsToDataFrame() %>% write.csv(output)
}
xml2csv("../data/gaming/Posts.xml",
"../data/Posts-Gaming.csv")
xml2csv("../data/gaming/Users.xml",
"../data/Users-Gaming.csv")
xml2csv("../data/chess/Posts.xml",
"../data/Posts-Chess.csv")
xml2csv("../data/chess/Users.xml",
"../data/Users-Chess.csv")
xml2csv("../data/bioinformatics/Posts.xml",
"../data/Posts-Bioinformatics.csv")
xml2csv("../data/bioinformatics/Users.xml",
"../data/Users-Bioinformatics.csv")
xml2csv("../data/gaming/Posts-eloelo.xml",
"../data/Posts-Gaming.csv")
getwd()
setwd()
install.packages("here")
library(here)
here("..", "data", "gaming", "Posts.xml")
here("data", "gaming", "Posts.xml")
xml2csv(here("data", "gaming", "Posts.xml"),
here("data", "Posts-Gaming.csv"))
xml2csv(here("data", "gaming", "Users.xml"),
here("data", "Users-Gaming.csv"))
x <- 'test'
f('Abc {x} abc')
fstring)
fstring_
library(fstrings)
install.packages("fstrings")
library(fstrings)
install.packages("fstring")
"ala" + " " + "ma" + " " + "kota"
source('C:/Users/48600/MAD/PDU/pdu-pd3/union-find/xml2csv.r')
library(XML)
library(dplyr)
library(here)
xml2csv <- function(input,output){
xmlParse(input) %>% getNodeSet(path = "//row") %>%
XML:::xmlAttrsToDataFrame() %>% write.csv(output)
}
forum_names <- c("gaming", "chess", "bioinformatics")
for (forum_name in forum_names) {
xml2csv(here("data", forum_name, "Posts.xml"),
here("data", paste("Posts-", forum_name, ".csv", sep="")))
xml2csv(here("data", forum_name, "Users.xml"),
here("data", paste("Users-", forum_name, ".csv", sep="")))
}
library(dplyr)
library(here)
# Wczytuję ramki Posts i Users z odpowiedniej bazy danych. W ten sposób mogę
# napisać jeden kod do wszystkich baz danych i podmieniać jedynie ścieżki lub
# pliki znajdujące się pod daną ścieżką.
Posts <- read.csv(here("data", "Posts-Bioinformatics.csv"))
Users <- read.csv(here("data", "Users-Bioinformatics.csv"))
# Biorę tylko dane potrzebne do algorytmu. Bazy danych są duże i jest potrzeba
# oszczędzania pamięci.
PostsUseful <- (
filter(Posts,PostTypeId == 2) %>% select(OwnerUserId,Id,ParentId) %>%
rename(AnsUserId = OwnerUserId,AnsId = Id,Id = ParentId) %>%
inner_join(Posts,by = "Id") %>%
select(AnsUserId,OwnerUserId) %>% rename(QuesUserId = OwnerUserId) %>%
# Pozbywam się zepsutych obserwacji.
filter(!is.na(AnsUserId) & !is.na(QuesUserId))
)
UsersUseful <- (
select(Users,Id) %>% filter(Id > 0)
)
# Zapisuję z powrotem do pliku, w formacie .csv ,ponieważ z nim potrafię
# pracować w innych, szybszych językach programowania. Find & Union jest
# szybkie, ale w R i tak bym czekał wieki aż się wykona, więc zdecydowałem, że
# rozdzielę projekt między kilka różnych języków programowania.
write.csv(PostsUseful, here("data", "wyniki", "Edges.csv"),
row.names = FALSE)
write.csv(UsersUseful, here("data", "wyniki", "Vertices.csv"),
row.names = FALSE)
library(dplyr)
library(here)
# Wczytuję ramki Posts i Users z odpowiedniej bazy danych. W ten sposób mogę
# napisać jeden kod do wszystkich baz danych i podmieniać jedynie ścieżki lub
# pliki znajdujące się pod daną ścieżką.
Posts <- read.csv(here("data", "Posts-Bioinformatics.csv"))
Users <- read.csv(here("data", "Users-Bioinformatics.csv"))
# Biorę tylko dane potrzebne do algorytmu. Bazy danych są duże i jest potrzeba
# oszczędzania pamięci.
PostsUseful <- (
filter(Posts,PostTypeId == 2) %>% select(OwnerUserId,Id,ParentId) %>%
rename(AnsUserId = OwnerUserId,AnsId = Id,Id = ParentId) %>%
inner_join(Posts,by = "Id") %>%
select(AnsUserId,OwnerUserId) %>% rename(QuesUserId = OwnerUserId) %>%
# Pozbywam się zepsutych obserwacji.
filter(!is.na(AnsUserId) & !is.na(QuesUserId))
)
UsersUseful <- (
select(Users,Id) %>% filter(Id > 0)
)
# Zapisuję z powrotem do pliku, w formacie .csv ,ponieważ z nim potrafię
# pracować w innych, szybszych językach programowania. Find & Union jest
# szybkie, ale w R i tak bym czekał wieki aż się wykona, więc zdecydowałem, że
# rozdzielę projekt między kilka różnych języków programowania.
write.csv(PostsUseful, here("data", "wyniki", "Edges.csv"),
row.names = FALSE)
write.csv(UsersUseful, here("data", "wyniki", "Vertices.csv"),
row.names = FALSE)
source('C:/Users/48600/MAD/PDU/pdu-pd3/union-find/xml2csv.r')
source('C:/Users/48600/MAD/PDU/pdu-pd3/union-find/xml2csv.r')
library(dplyr)
library(here)
f_name <- "bioinformatics"
# Wczytuję ramki Posts i Users z odpowiedniej bazy danych. W ten sposób mogę
# napisać jeden kod do wszystkich baz danych i podmieniać jedynie ścieżki lub
# pliki znajdujące się pod daną ścieżką.
Posts <- read.csv(here("data", "Posts-Bioinformatics.csv"))
Users <- read.csv(here("data", "Users-Bioinformatics.csv"))
# Biorę tylko dane potrzebne do algorytmu. Bazy danych są duże i jest potrzeba
# oszczędzania pamięci.
PostsUseful <- (
filter(Posts,PostTypeId == 2) %>% select(OwnerUserId,Id,ParentId) %>%
rename(AnsUserId = OwnerUserId,AnsId = Id,Id = ParentId) %>%
inner_join(Posts,by = "Id") %>%
select(AnsUserId,OwnerUserId) %>% rename(QuesUserId = OwnerUserId) %>%
# Pozbywam się zepsutych obserwacji.
filter(!is.na(AnsUserId) & !is.na(QuesUserId))
)
UsersUseful <- (
select(Users,Id) %>% filter(Id > 0)
)
# Zapisuję z powrotem do pliku, w formacie .csv ,ponieważ z nim potrafię
# pracować w innych, szybszych językach programowania. Find & Union jest
# szybkie, ale w R i tak bym czekał wieki aż się wykona, więc zdecydowałem, że
# rozdzielę projekt między kilka różnych języków programowania.
write.csv(PostsUseful, here("data", "wyniki", paste("Edges-", f_name, ".csv", sep="")),
row.names = FALSE)
write.csv(UsersUseful, here("data", "wyniki", paste("Vertices-", f_name, ".csv", sep="")),
row.names = FALSE)
library(dplyr)
library(here)
forum_names <- c("gaming", "chess", "bioinformatics")
for (f_name in forum_names) {
Posts <- read.csv(here("data", paste("Posts-", f_name, ".csv")))
Users <- read.csv(here("data", paste("Users-", f_name, ".csv")))
# Biorę tylko dane potrzebne do algorytmu. Bazy danych są duże i jest potrzeba
# oszczędzania pamięci.
PostsUseful <- (
filter(Posts,PostTypeId == 2) %>% select(OwnerUserId,Id,ParentId) %>%
rename(AnsUserId = OwnerUserId,AnsId = Id,Id = ParentId) %>%
inner_join(Posts,by = "Id") %>%
select(AnsUserId,OwnerUserId) %>% rename(QuesUserId = OwnerUserId) %>%
# Pozbywam się zepsutych obserwacji.
filter(!is.na(AnsUserId) & !is.na(QuesUserId))
)
UsersUseful <- (
select(Users,Id) %>% filter(Id > 0)
)
# Zapisuję z powrotem do pliku, w formacie .csv ,ponieważ z nim potrafię
# pracować w innych, szybszych językach programowania. Find & Union jest
# szybkie, ale w R i tak bym czekał wieki aż się wykona, więc zdecydowałem, że
# rozdzielę projekt między kilka różnych języków programowania.
write.csv(PostsUseful, here("data", "wyniki", paste("Edges-", f_name, ".csv", sep="")),
row.names = FALSE)
write.csv(UsersUseful, here("data", "wyniki", paste("Vertices-", f_name, ".csv", sep="")),
row.names = FALSE)
}
library(dplyr)
library(here)
forum_names <- c("gaming", "chess", "bioinformatics")
for (f_name in forum_names) {
Posts <- read.csv(here("data", paste("Posts-", f_name, ".csv", sep="")))
Users <- read.csv(here("data", paste("Users-", f_name, ".csv", sep="")))
# Biorę tylko dane potrzebne do algorytmu. Bazy danych są duże i jest potrzeba
# oszczędzania pamięci.
PostsUseful <- (
filter(Posts,PostTypeId == 2) %>% select(OwnerUserId,Id,ParentId) %>%
rename(AnsUserId = OwnerUserId,AnsId = Id,Id = ParentId) %>%
inner_join(Posts,by = "Id") %>%
select(AnsUserId,OwnerUserId) %>% rename(QuesUserId = OwnerUserId) %>%
# Pozbywam się zepsutych obserwacji.
filter(!is.na(AnsUserId) & !is.na(QuesUserId))
)
UsersUseful <- (
select(Users,Id) %>% filter(Id > 0)
)
# Zapisuję z powrotem do pliku, w formacie .csv ,ponieważ z nim potrafię
# pracować w innych, szybszych językach programowania. Find & Union jest
# szybkie, ale w R i tak bym czekał wieki aż się wykona, więc zdecydowałem, że
# rozdzielę projekt między kilka różnych języków programowania.
write.csv(PostsUseful, here("data", "wyniki", paste("Edges-", f_name, ".csv", sep="")),
row.names = FALSE)
write.csv(UsersUseful, here("data", "wyniki", paste("Vertices-", f_name, ".csv", sep="")),
row.names = FALSE)
}
library(dplyr)
library(here)
forum_names <- c("gaming", "chess", "bioinformatics")
for (f_name in forum_names) {
Posts <- read.csv(here("data", paste("Posts-", f_name, ".csv", sep="")))
Users <- read.csv(here("data", paste("Users-", f_name, ".csv", sep="")))
# Biorę tylko dane potrzebne do algorytmu. Bazy danych są duże i jest potrzeba
# oszczędzania pamięci.
PostsUseful <- (
filter(Posts,PostTypeId == 2) %>% select(OwnerUserId,Id,ParentId) %>%
rename(AnsUserId = OwnerUserId,AnsId = Id,Id = ParentId) %>%
inner_join(Posts,by = "Id") %>%
select(AnsUserId,OwnerUserId) %>% rename(QuesUserId = OwnerUserId) %>%
# Pozbywam się zepsutych obserwacji.
filter(!is.na(AnsUserId) & !is.na(QuesUserId))
)
UsersUseful <- (
select(Users,Id) %>% filter(Id > 0)
)
# Zapisuję z powrotem do pliku, w formacie .csv ,ponieważ z nim potrafię
# pracować w innych, szybszych językach programowania. Find & Union jest
# szybkie, ale w R i tak bym czekał wieki aż się wykona, więc zdecydowałem, że
# rozdzielę projekt między kilka różnych języków programowania.
write.csv(PostsUseful, here("data", "wyniki", paste("Edges-", f_name, ".csv", sep="")),
row.names = FALSE)
write.csv(UsersUseful, here("data", "wyniki", paste("Vertices-", f_name, ".csv", sep="")),
row.names = FALSE)
}
library(dplyr)
library(here)
forum_names <- c("gaming", "chess", "bioinformatics")
for (f_name in forum_names) {
Posts <- read.csv(here("data", paste("Posts-", f_name, ".csv", sep="")))
Users <- read.csv(here("data", paste("Users-", f_name, ".csv", sep="")))
# Biorę tylko dane potrzebne do algorytmu. Bazy danych są duże i jest potrzeba
# oszczędzania pamięci.
PostsUseful <- (
filter(Posts,PostTypeId == 2) %>% select(OwnerUserId,Id,ParentId) %>%
rename(AnsUserId = OwnerUserId,AnsId = Id,Id = ParentId) %>%
inner_join(Posts,by = "Id") %>%
select(AnsUserId,OwnerUserId) %>% rename(QuesUserId = OwnerUserId) %>%
# Pozbywam się zepsutych obserwacji.
filter(!is.na(AnsUserId) & !is.na(QuesUserId))
)
UsersUseful <- (
select(Users,Id) %>% filter(Id > 0)
)
# Zapisuję z powrotem do pliku, w formacie .csv ,ponieważ z nim potrafię
# pracować w innych, szybszych językach programowania. Find & Union jest
# szybkie, ale w R i tak bym czekał wieki aż się wykona, więc zdecydowałem, że
# rozdzielę projekt między kilka różnych języków programowania.
write.csv(PostsUseful, here("data", "wyniki", paste("Edges-", f_name, ".csv", sep="")),
row.names = FALSE)
write.csv(UsersUseful, here("data", "wyniki", paste("Vertices-", f_name, ".csv", sep="")),
row.names = FALSE)
}
library(XML)
library(dplyr)
library(here)
xml2csv <- function(input,output){
xmlParse(input) %>% getNodeSet(path = "//row") %>%
XML:::xmlAttrsToDataFrame() %>% write.csv(output)
}
forum_names <- c("health")
for (forum_name in forum_names) {
xml2csv(here("data", forum_name, "Posts.xml"),
here("data", paste("Posts-", forum_name, ".csv", sep="")))
xml2csv(here("data", forum_name, "Users.xml"),
here("data", paste("Users-", forum_name, ".csv", sep="")))
}
library(dplyr)
library(here)
forum_names <- c("health")
for (f_name in forum_names) {
Posts <- read.csv(here("data", paste("Posts-", f_name, ".csv", sep="")))
Users <- read.csv(here("data", paste("Users-", f_name, ".csv", sep="")))
# Biorę tylko dane potrzebne do algorytmu. Bazy danych są duże i jest potrzeba
# oszczędzania pamięci.
PostsUseful <- (
filter(Posts,PostTypeId == 2) %>% select(OwnerUserId,Id,ParentId) %>%
rename(AnsUserId = OwnerUserId,AnsId = Id,Id = ParentId) %>%
inner_join(Posts,by = "Id") %>%
select(AnsUserId,OwnerUserId) %>% rename(QuesUserId = OwnerUserId) %>%
# Pozbywam się zepsutych obserwacji.
filter(!is.na(AnsUserId) & !is.na(QuesUserId))
)
UsersUseful <- (
select(Users,Id) %>% filter(Id > 0)
)
# Zapisuję z powrotem do pliku, w formacie .csv ,ponieważ z nim potrafię
# pracować w innych, szybszych językach programowania. Find & Union jest
# szybkie, ale w R i tak bym czekał wieki aż się wykona, więc zdecydowałem, że
# rozdzielę projekt między kilka różnych języków programowania.
write.csv(PostsUseful, here("data", "wyniki", paste("Edges-", f_name, ".csv", sep="")),
row.names = FALSE)
write.csv(UsersUseful, here("data", "wyniki", paste("Vertices-", f_name, ".csv", sep="")),
row.names = FALSE)
}
f_name <- "bioinformatics"
Posts <- read.csv(here("data", paste("Posts-", f_name, ".csv", sep="")))
Users <- read.csv(here("data", paste("Users-", f_name, ".csv", sep="")))
head(Users)
View(Users)
View(Users)
View(Posts)
View(Posts)
library(dplyr)
Posts %>% filter(OwnerUserId=selected_user_id) %>% view()
selected_user_id <- 1
Posts %>% filter(OwnerUserId=selected_user_id) %>% View()
Posts %>% filter(OwnerUserId==selected_user_id) %>% View()
selected_user_id <- 2
Posts %>% filter(OwnerUserId==selected_user_id) %>% View()
selected_user_id <- 62
Posts %>% filter(OwnerUserId==selected_user_id) %>% View()
selected_user_id <- 10604
Posts %>% filter(OwnerUserId==selected_user_id) %>% View()
library(XML)
library(dplyr)
library(here)
xml2csv <- function(input,output){
xmlParse(input) %>% getNodeSet(path = "//row") %>%
XML:::xmlAttrsToDataFrame() %>% write.csv(output)
}
forum_names <- c("beer", "bicycles", "coffee", "fitness", "lifehacks", "music", "photo", "travel")
for (forum_name in forum_names) {
xml2csv(here("data", forum_name, "Posts.xml"),
here("data", paste("Posts-", forum_name, ".csv", sep="")))
xml2csv(here("data", forum_name, "Users.xml"),
here("data", paste("Users-", forum_name, ".csv", sep="")))
}
library(dplyr)
library(here)
forum_names <- c("beer", "bicycles", "coffee", "fitness", "lifehacks", "music", "photo", "travel")
for (f_name in forum_names) {
Posts <- read.csv(here("data", paste("Posts-", f_name, ".csv", sep="")))
Users <- read.csv(here("data", paste("Users-", f_name, ".csv", sep="")))
# Biorę tylko dane potrzebne do algorytmu. Bazy danych są duże i jest potrzeba
# oszczędzania pamięci.
PostsUseful <- (
filter(Posts,PostTypeId == 2) %>% select(OwnerUserId,Id,ParentId) %>%
rename(AnsUserId = OwnerUserId,AnsId = Id,Id = ParentId) %>%
inner_join(Posts,by = "Id") %>%
select(AnsUserId,OwnerUserId) %>% rename(QuesUserId = OwnerUserId) %>%
# Pozbywam się zepsutych obserwacji.
filter(!is.na(AnsUserId) & !is.na(QuesUserId))
)
UsersUseful <- (
select(Users,Id) %>% filter(Id > 0)
)
# Zapisuję z powrotem do pliku, w formacie .csv ,ponieważ z nim potrafię
# pracować w innych, szybszych językach programowania. Find & Union jest
# szybkie, ale w R i tak bym czekał wieki aż się wykona, więc zdecydowałem, że
# rozdzielę projekt między kilka różnych języków programowania.
write.csv(PostsUseful, here("data", "wyniki", paste("Edges-", f_name, ".csv", sep="")),
row.names = FALSE)
write.csv(UsersUseful, here("data", "wyniki", paste("Vertices-", f_name, ".csv", sep="")),
row.names = FALSE)
}
library(XML)
library(dplyr)
library(here)
xml2csv <- function(input,output){
xmlParse(input) %>% getNodeSet(path = "//row") %>%
XML:::xmlAttrsToDataFrame() %>% write.csv(output)
}
forum_names <- c("vegetarianism", "pets", "parenting", "cooking", "bitcoin", "astronomy", "literature", "sports")
for (forum_name in forum_names) {
xml2csv(here("data", forum_name, "Posts.xml"),
here("data", paste("Posts-", forum_name, ".csv", sep="")))
xml2csv(here("data", forum_name, "Users.xml"),
here("data", paste("Users-", forum_name, ".csv", sep="")))
}
c("vegetarianism", "pets", "parenting", "cooking", "bitcoin", "astronomy", "literature", "sports")
library(dplyr)
library(here)
forum_names <-  c("vegetarianism", "pets", "parenting", "cooking", "bitcoin", "astronomy", "literature", "sports")
for (f_name in forum_names) {
Posts <- read.csv(here("data", paste("Posts-", f_name, ".csv", sep="")))
Users <- read.csv(here("data", paste("Users-", f_name, ".csv", sep="")))
# Biorę tylko dane potrzebne do algorytmu. Bazy danych są duże i jest potrzeba
# oszczędzania pamięci.
PostsUseful <- (
filter(Posts,PostTypeId == 2) %>% select(OwnerUserId,Id,ParentId) %>%
rename(AnsUserId = OwnerUserId,AnsId = Id,Id = ParentId) %>%
inner_join(Posts,by = "Id") %>%
select(AnsUserId,OwnerUserId) %>% rename(QuesUserId = OwnerUserId) %>%
# Pozbywam się zepsutych obserwacji.
filter(!is.na(AnsUserId) & !is.na(QuesUserId))
)
UsersUseful <- (
select(Users,Id) %>% filter(Id > 0)
)
# Zapisuję z powrotem do pliku, w formacie .csv ,ponieważ z nim potrafię
# pracować w innych, szybszych językach programowania. Find & Union jest
# szybkie, ale w R i tak bym czekał wieki aż się wykona, więc zdecydowałem, że
# rozdzielę projekt między kilka różnych języków programowania.
write.csv(PostsUseful, here("data", "wyniki", paste("Edges-", f_name, ".csv", sep="")),
row.names = FALSE)
write.csv(UsersUseful, here("data", "wyniki", paste("Vertices-", f_name, ".csv", sep="")),
row.names = FALSE)
}
library(dplyr)
library(here)
getUsefulPostsData <- function(input,output){
read.csv(input) %>% select(OwnerUserId,PostTypeId) %>%
filter(PostTypeId == 1 | PostTypeId == 2) %>% filter(!is.na(OwnerUserId)) %>%
write.csv(output,row.names = FALSE)
}
forum_names <- c(
"gaming",
"chess",
"bioinformatics",
"health",
"beer",
"bicycles",
"coffee",
"fitness",
"lifehacks",
"music",
"photo",
"travel",
"vegetarianism",
"pets",
"parenting",
"cooking",
"bitcoin",
"astronomy",
"literature",
"sports"
)
for (forum_name in forum_names) {
getUsefulPostsData(here("data", paste("Posts-", forum_name, ".csv", sep="")),
here("data", "wyniki", paste("PostsForCounting-", forum_name, ".csv", sep="")))
}
getUsefulPostsData("E:/RStudio/Trzeci projekt/bazy danych/Posts-AI.csv",
"E:/RStudio/Trzeci projekt/wyniki/PostsForCounting.csv")
source('C:/Users/48600/MAD/PDU/pdu-pd3/union-find/xml2csv.r')
